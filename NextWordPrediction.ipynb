{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pip install anvil-uplink"
      ],
      "metadata": {
        "id": "gwidZwDhMWAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSGOSaVmD038"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import anvil.server"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ4Fw_wsa9Ea",
        "outputId": "2e45dc37-07be-40c6-e435-fadc66d466e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "text_df = pd.read_csv(\"/content/gdrive/My Drive/Data_berita.csv\")\n",
        "\n",
        "text = list(text_df.content.values)\n",
        "joined_text = ' '.join(text)\n",
        "\n",
        "partial_text = joined_text[:250407]\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(partial_text.lower())\n",
        "\n",
        "unique_tokens = np.unique(tokens)\n",
        "unique_tokens_index = {token: idx for idx, token in enumerate(unique_tokens)}\n",
        "\n",
        "n_words = 10\n",
        "input_words = []\n",
        "next_words = []\n",
        "\n",
        "for i in range(len(tokens) - n_words) :\n",
        "  input_words.append(tokens[i:i + n_words])\n",
        "  next_words.append(tokens[i + n_words])\n",
        "\n",
        "x = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
        "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)\n",
        "\n",
        "for i, words in enumerate(input_words) :\n",
        "  for j, word in enumerate(words) :\n",
        "    x[i, j, unique_tokens_index[word]] = 1\n",
        "  y[i, unique_tokens_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "QO-9Yc77dTEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
        "layers = 3\n",
        "rep = layers - 2\n",
        "if rep > 2 :\n",
        "    for l in range(rep) :\n",
        "        model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=['accuracy'])\n",
        "history = model.fit(x,y,batch_size = 128, epochs = 200, shuffle = True)\n",
        "model.save('mymodel.h5')"
      ],
      "metadata": {
        "id": "EuUJ_PTRelaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-train the model\n",
        "# del model\n",
        "# model = load_model('mymodel.h5')\n",
        "# history = model.fit(x,y,batch_size = 128, epochs = 50, shuffle = True)\n",
        "# model.save('mymodel.h5')"
      ],
      "metadata": {
        "id": "42xJyYSmiqwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw the Graph\n",
        "\n",
        "accuracy_list = history.history['accuracy']\n",
        "loss_list = history.history['loss']\n",
        "\n",
        "# Create x-axis values (epochs)\n",
        "epochs = range(1, len(accuracy_list) + 1)\n",
        "\n",
        "# Plot epoch vs accuracy\n",
        "plt.plot(epochs, accuracy_list, 'b', label='Accuracy')\n",
        "plt.title('Epoch vs Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create x-axis values (epochs)\n",
        "epochs = range(1, len(loss_list) + 1)\n",
        "\n",
        "# Plot epoch vs accuracy\n",
        "plt.plot(epochs, loss_list, 'b', label='Loss')\n",
        "plt.title('Epoch vs Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pccGz5kdiylU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Next word\n",
        "\n",
        "def predict_next_word(input_text, n_best):\n",
        "    input_text = input_text.lower()\n",
        "    x = np.zeros((1, n_words, len(unique_tokens)))\n",
        "    for i, word in enumerate(input_text.split()):\n",
        "        if word in unique_tokens_index:\n",
        "            x[0, i, unique_tokens_index[word]] = 1\n",
        "\n",
        "    predictions = model.predict(x)[0]\n",
        "    top_n_indices = np.argpartition(predictions, -n_best)[-n_best:]\n",
        "    top_n_words = [unique_tokens[i] for i in top_n_indices]\n",
        "    top_n_weights = [predictions[i] for i in top_n_indices]\n",
        "\n",
        "    # Sort the predicted words based on weights in descending order\n",
        "    sorted_words_weights = sorted(zip(top_n_words, top_n_weights), key=lambda x: x[1], reverse=True)\n",
        "    sorted_words, sorted_weights = zip(*sorted_words_weights)\n",
        "\n",
        "    res_arr = []\n",
        "    # Print the predicted words and their weights\n",
        "    for word, weight in zip(sorted_words, sorted_weights):\n",
        "        res_arr.append(f\"{word} - Weight: {weight * 100} %\")\n",
        "        # print(f\"{word} - Weight: {weight * 100} %\")\n",
        "\n",
        "    return res_arr"
      ],
      "metadata": {
        "id": "9mERFytzizSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model\n",
        "\n",
        "model = load_model(\"/content/gdrive/My Drive/mymodel.h5\")"
      ],
      "metadata": {
        "id": "0ktFl26S7FzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.connect('server_LVEBX45C7W3XPYEU7HNV5YPO-EMOCVIU5JIAIFHFJ')"
      ],
      "metadata": {
        "id": "FsA8LQKfjDBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7847d0e8-bb3a-4d42-f6e9-b0fc20a33b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable\n",
        "def predict_word(input_text) :\n",
        "  return '\\n'.join(predict_next_word(input_text,5))"
      ],
      "metadata": {
        "id": "Sa_RLtsInJpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.wait_forever()"
      ],
      "metadata": {
        "id": "XZ766X9Znxua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144d4b0e-e492-4bb8-bdb2-ba9dcbed511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-95cac3476493>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manvil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anvil/server.py\u001b[0m in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}